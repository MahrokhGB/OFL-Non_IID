conda activate ofliid

1. Generate data
from the main directory:
python dataset/generate_emnist.py
NOTE: select alpha (0.4 or None) in the generate_emnist function.



General params to tune
-m', "--model", type=str, default="cnn")
parser.add_argument('-lbs', "--batch_size", type=int, default=10)
parser.add_argument('-lr', "--local_learning_rate", type=float, default=0.005,
                    help="Local learning rate")
parser.add_argument('-gr', "--global_rounds", type=int, default=2000)
parser.add_argument('-ls', "--local_epochs", type=int, default=1,
                    help="Multiple update steps in one local epoch.")
parser.add_argument('-algo', "--algorithm", type=str, default="FedAvg")
parser.add_argument('-jr', "--join_ratio", type=float, default=1.0,
                    help="Ratio of clients per round")


parser.add_argument('-sfn', "--save_folder_name", type=str, default='items')


parser.add_argument('-bnpc', "--batch_num_per_client", type=int, default=2)
parser.add_argument('-nnc', "--num_new_clients", type=int, default=0)
parser.add_argument('-fte', "--fine_tuning_epoch", type=int, default=0)

bash
conda activate ofliid
cd Simulations/OFL-Non_IID/system


1. FedAvg
python main.py -nc 80 -nb 64 -data femnist_med -m cnn -algo FedAvg -gr 2000 -did 0 -rs 0
0.4: random seeds 0, 5, 10, 15, 20:

2. MAML
specific params:
'-bt', "--beta", type=float, default=0.0, Second learning rate of Per-FedAvg
-lam', "--lamda", type=float, default=1.0, Regularization weight# NOTE: shouldn't be 0?
'-lrp', "--p_learning_rate", type=float, default=0.01,
                    help="personalized learning rate to caculate theta aproximately using K steps"

# NOTE: lbs should be less than half of the training dataset size
python -u main.py -lbs 100 -nc 80 -nb 64 -data emnist4 -algo PerAvg -gr 2000 -m dnn -did 1 -bt 0.001 -go dnn > femnist_reduced_peravg.out 2>&1 &


# tune beta
--- 0.4: (beta, test acc) ---
DNN:
CNN: (1e-4, ), (1e-3, ), (1e-2, ), (1e-1, ), (1, ), (10, )
CNN with beta=1e-2, random seeds 0, 5, 10, 15, 20: 0.8015, 0.851, 0.823, 0.860, 0.767


bash
conda activate ofliid
cd Simulations/OFL-Non_IID/system


3. MTL
'-itk', "--itk", type=int, default=4000, The iterations for solving quadratic subproblems
python -u main.py -lbs 100 -nc 80 -nb 64 -data emnist4 -algo FedMTL -gr 100 -m cnn -itk 4000 -lr 0.01 -did 1 -rs 0
alpha=0.4: 0.72
NOTE: increased learning rate from default, reduced gr